[tool.poetry]
name = "zdatasets"
version = "0.1.2.dev1"
description = "Dataset SDK for consistent read/write [batch, online, streaming] data."
classifiers = [
  "Development Status :: 2 - Pre-Alpha",
  "Intended Audience :: Developers",
  "License :: OSI Approved :: Apache Software License",
  "Natural Language :: English",
  "Programming Language :: Python :: 3.9",
]
authors = ["Taleb Zeghmi"]
readme = "README.md"

[[tool.poetry.packages]]
include = "datasets"

# https://packaging.python.org/guides/creating-and-discovering-plugins/
[tool.poetry.plugins]
[tool.poetry.plugins."datasets.plugins"]
batch_dataset = "datasets.plugins:BatchDataset"
flow_dataset = "datasets.plugins:FlowDataset"
hive_dataset = "datasets.plugins:HiveDataset"

[tool.poetry.plugins."datasets.executors"]
metaflow_executor = "datasets.plugins:MetaflowExecutor"

[tool.poetry.dependencies]
python = ">=3.9.0,<3.11"
pandas = ">=1.4.0"
pyarrow = ">=6.0.0"
dask = { version = ">=2021.9.1", optional = true }
pyspark = { version = "^3.2.0", optional = true }
importlib-metadata = ">=4.8.1"
click = ">=7.0,<8.1"
s3fs = ">=2022.1.0"
awswrangler = ">=2.12.0"

[tool.poetry.dev-dependencies]
mypy = ">=0.910"
black = ">=21.7b0"
flake8 = ">=3.9.2"
isort = ">=5.9.3"
pytest = ">=6.2.4"
pytest-cov = ">=2.12.1"
seed-isort-config = ">=2.2"
pre-commit = ">=2.15"
pytest-depends = ">=1.0.1"
moto = {extras = ["s3"], version = ">=2.3.1"}

[tool.poetry.extras]
doc = ["sphinx", "sphinx_rtd_theme"]
metaflow = ["zillow-metaflow"]
dask = ["dask"]
spark = ["pyspark"]

[tool.isort]
known_first_party = 'datasets'
known_third_party = ["datasets", "numpy", "orbital_core", "pandas"]
multi_line_output = 3
lines_after_imports = 2
force_grid_wrap = 0
combine_as_imports = true
include_trailing_comma = true

[tool.black]
line-length = 110
include = '\.pyi?$'
exclude = '''
/(
    \.git
  | \.mypy_cache
  | \.venv
  | _build
  | buck-out
  | build
  | dist
)/
'''

[build-system]
requires = ["poetry>=1.1.10"]
build-backend = "poetry.masonry.api"
